Elasticsearch makes differentials repositories only. To make a monthly full snapshot, you will need to create a new repository as full snapsjhots are made on new repositories
this sample was made for <Site>

Create the share
	SSH log into the server with elasticsearch
	$ sudo su
	$ mkdir /elasticsearch-backup
	$ chown -R elasticsearch:elasticsearch /elasticsearch-backup/
	$ cd /
	$ find -name "elasticsearch.yml"
		//* /opt/elasticsearch-7.5.0/config/elasticsearch.yml
	$ nano /opt/elasticsearch-7.5.0/config/elasticsearch.yml
		# ----------------------------------- Paths ------------------------------------
		#
		# Path to directory where to store the data (separate multiple locations by comma):
		#
		#path.data: /path/to/data
		#
		# Path to log files:
		#
		#path.logs: /path/to/logs
		#Added by Rick 01/16/2020 for backing up elasticsearch
		path.repo: ["/elasticsearch-backup"]
	restart elasticsearch
Create the repository
	In you laptop:
	open browser and go to https://<Site>
	Click on "manage" -> "Snapsots and Restore"
	Click on "<Site> a repository"
	Type in the "repository name" box:
		elasticsearch-backup
	Select "Shared file system"
	Click on "Next"
	Type in the "location" box:
		/elasticsearch-backup
	Enable compression
	Click on "<Site>"
Verify that the repository was created
	In your laptop:
	open browser and go to https://<Site>
	Click on the "Dev tools" icon
	Click on "console"
	in the left pane, type
		GET /_snapshot/_all
			//* {
			//*  "elasticsearch-backup" : {
			//*    "type" : "fs",
			//*     "settings" : {
			//*       "compress" : "true",
			//*       "location" : "/elasticsearch-backup"
			//*     }
			//*   }
			//* }
Create a snapshot manually
	SSH log into the server with elasticsearch
	$ sudo su
	$ curl -XPUT "http://<Site>:9200/_snapshot/elasticsearch-backup/snapshot-0001?wait_for_completion=true"

Create a policy to make snapshots daily (This throws an error)
	In your laptop:
	open browser and go to https://<Site>:9200
	Click on "Snapshots and restore"
	Click on the "Snapshots" tab
	Click on "Create policy"
	In the "Policy Name" box, type
		daily-snapshots
	In the "Snapshot name" box, type
		<<Site>-es-{now/d}>
	In the "Repository", select
		elasticsearch-backup
	In the schedule, set a time and select every day
	CLick on "Next"

create a backup script
	SSH log into the server with elasticsearch
	$ sudo su
	$ cd /
	$ nano elasticsearch-backup.sh
#!/bin/bash
#SCRIPT NAME: /elasticsearch-backup.sh
#PURPOSE: backup elasticsearch data to the drobo in the <Location> Office
#CREATED ON: 01/16/2020
#CREATED BY: Rick Yamamoto
#VERSION: 1 of 1
#INTRUCTIONS: copy this script onto the root of a elasticsearch server. Then create a crontab job to autoexecute it everyday. Then:
#	mkdir /elasticsearch-backup
#	$ chown -R elasticsearch:elasticsearch /elasticsearch-backup/
#	nano /opt/elasticsearch-7.5.0/config/elasticsearch.yml
#		path.repo: ["/elasticsearch-backup"]
# 	restart elasticsearch
#	using kibana, <Site> the repository name "elasticsearch-backup" and point it to /elasticsearch-backup
#DATA REPOSITORY LOCATION: <Location>:\XXX.XXX.XXX.87\backup\<Site>
#REQUIREMENTS: DATABASE ENGINE MUST BE MYSQL
#              #Set the days variables to define which day of the week to run the backups
#              sudo crontab -e
#                 01 03 *   *   *    /bin/bash /elasticsearch-backup.sh
#              #  Mn Hr DoM Mon DoW
#              yum install sshpass or apt-get install sshpass or (see https://www.tecmint.com/sshpass-non-interactive-ssh-login-shell-script-ssh-password/)
#              get the fullpath for sshpass ($ which sshpass) and replace it in the script.
#              wget http://caspian.dotconf.net/menu/Software/SendEmail/sendEmail-v1.56.tar.gz
#              yum install 'perl(Net::SSLeay)' 'perl(IO::Socket::SSL)' or apt-get install 'perl(Net::SSLeay)' 'perl(IO::Socket::SSL)' or apt-get install libnet-ssleay-perl libio-socket-ssl-perl
#              tar -xvzf sendEmail-v1.56.tar.gz
#              sudo mv sendEmail-v1.56/sendEmail /usr/bin
#              sudo nano /etc/profile.d/addpath.sh
#                 export PATH=$PATH:/usr/local/bin:/usr/local/sbin
#              nano /usr/local/bin/sendEmail
#                 replace: if (! IO::Socket::SSL->start_SSL($SERVER, SSL_version => 'SSLv3 TLSv1')) {     with: if (! IO::Socket::SSL->start_SSL($SERVER, SSL_version => 'TLSv1')) {
#              #connect via ssh to XXX.XXX.XXX.243:<Port> at least one to install the ssh key.
#STARTING...
PATH=$PATH:/usr/local/bin:/usr/bin

vwwwroot1="$HOSTNAME"
vip1=$(ip route get 8.8.8.8 | awk 'NR==1 {print $NF}')
vdate1=$(date "+%Y-%m-%d")
vtime1=$(TZ=US/Eastern date '+%H:%M:%S')
vfilename1=$vdate1-elasticsearch-backup.tar.gz

#VERIFYING THAT DIRECTORY EXIST ON DROBO AND CREATE IF IT DOES NOT
sshpass -p '<Password>' ssh -oStrictHostKeyChecking=no -p <PortNumber> <Username>@XXX.XXX.XXX.243 /bin/mkdir -p /mnt/shares/drobo/$vwwwroot1

#CREATING A SNAPSHOT OF ELASTICSEARCH OF ALL INDEXES
echo CREATNG THE SNAPSHOT
echo "===================="
echo curl -XPUT "http://<Site>:9200/_snapshot/elasticsearch-backup/snapshot-$vdate1?wait_for_completion=true"
vexitcode1=$?
if [ $vexitcode1 -ne 0 ] ; then
   echo "snapshot failed with exit code $vexitcode1"
   sendEmail -vv -o tls=yes -m "Error on $vdate1 when creating elasticsearch snapshot on $vwwwroot1($vip1):elasticsearch-backup/snapshot-$vdate1 -> snapshot failed with exit code $vexitcode1" -f <Email> -t <Email> -cc <Email> -s smtp.gmail.com:587 -xu <Email> -xp <Password> -u "$vwwwroot1($vip1):/elasticsearch-backup.sh snapshot Error: $vexitcode1" >> /var/log/sendEmail.log
   sshpass -p '<Password>' ssh -p <PortNumber> <Username>@XXX.XXX.XXX.243 "/bin/echo $vdate1 $vtime1 $(date "+%Y-%m-%d") $(TZ=US/Eastern date '+%H:%M:%S') EDT Elastic $vwwwroot1 Error:snapshot failed with exit code $vexitcode1 >> /mnt/shares/drobo/backupserver.log"
else
   #COMPATING THE SNAPSHOT
   echo " "
   echo COMPACTING THE SNAPSHOT
   echo "======================="
   cd /elasticsearch-backup
   tar cpPzf /tmp/$vfilename1 /elasticsearch-backup --after-date='1 days ago'
   vexitcode1=$?
   if [ $vexitcode1 -ne 0 ] ; then
      echo "tar failed with exit code $vexitcode1"
      rm -f /tmp/$vfilename1
      sendEmail -vv -o tls=yes -m "Error on $vdate1 when compressing /elasticsearch-backup on $vwwwroot1($vip1):/tmp/$vfilename1-> tar failed with exit code $vexitcode1" -f <Email> -t <Email> -cc <Email> -s smtp.gmail.com:587 -xu <Email> -xp <Password> -u "$vwwwroot1($vip1):/elasticsearch-backup.sh tar Error: $vexitcode1" >> /var/log/sendEmail.log
      sshpass -p '<Password>' ssh -p <PortNumber> <Username>@XXX.XXX.XXX.243 "/bin/echo $vdate1 $vtime1 $(date "+%Y-%m-%d") $(TZ=US/Eastern date '+%H:%M:%S') EDT Elastic $vwwwroot1 Error:tar failed with exit code $vexitcode1 >> /mnt/shares/drobo/backupserver.log"
   else
      echo "STARTING TRANSMISSION OF SNAPSHOT TO THE <Location> OFFICE"
      echo "======================================================="
      chmod 777 /tmp/$vfilename1
      vtime1=$(TZ=US/Eastern date '+%H:%M:%S') 
      sshpass -p '<Password>' scp -oStrictHostKeyChecking=no -P <PortNumber> -p /tmp/$vfilename1 <Username>@XXX.XXX.XXX.243:/mnt/shares/drobo/$vwwwroot1/
      vexitcode1=$?
      rm -f /tmp/$vfilename1
      if [ $vexitcode1 -ne 0 ] ; then
         echo "sshpass failed with exit code $vexitcode1"
         sendEmail -vv -o tls=yes -m "Error on $vdate1 when transmitting database backup from $vwwwroot1($vip1) to <Location>\\\\XXX.XXX.XXX.87\\backup\\$vwwwroot1\\$vfilename1.\n -> sshpass failed with exit code $vexitcode1" -f <Email> -t <Email> -cc <Email> -s smtp.gmail.com:587 -xu <Email> -xp <Password> -u "$vwwwroot1($vip1):/wordpress-backup.sh sshpass Error: $verrorcode1" >> /var/log/sendEmail.log
         sshpass -p '<Password>' ssh -p <PortNumber> <Username>@XXX.XXX.XXX.243 "/bin/echo $vdate1 $vtime1 $(date "+%Y-%m-%d") $(TZ=US/Eastern date '+%H:%M:%S') EDT Mysql $vwwwroot1 Error:sshpass failed with exit code $vexitcode1 >> /mnt/shares/drobo/backupserver.log"
      else
         echo "Backup finished without errors"
         sendEmail -vv -o tls=yes -m "Successfully backed up all indexes of elasticseach from $vwwwroot1 to <Location>\\\\XXX.XXX.XXX.87\\backup\\$vwwwroot1\\$vfilename1.\n $vdate1\n See <Location>Office\\\\XXX.XXX.XXX.87\\backup\\restore-procedure.txt for instructions on restore the backup" -f <Email> -t <Email> -s smtp.gmail.com:587 -xu <Email> -xp <Password> -u "$vwwwroot1($vip1):Successful backup of elasticsearch indexes was made on $vdate1" >> /var/log/sendEmail.log
         sshpass -p '<Password>' ssh -p <PortNumber> <Username>@XXX.XXX.XXX.243 "/bin/echo $vdate1 $vtime1 $(date "+%Y-%m-%d") $(TZ=US/Eastern date '+%H:%M:%S') EDT Mysql $vwwwroot1 Success: backed up elastic >> /mnt/shares/drobo/backupserver.log"
      fi
   fi
fi



